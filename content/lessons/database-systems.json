[
  {
    "id": "database-systems-lesson-1",
    "moduleSlug": "database-systems",
    "title": "Relational Model and Normalization",
    "order": 1,
    "objectives": [
      "Understand the principles of the relational model and its mathematical foundations",
      "Apply normalization rules to eliminate data redundancy and update anomalies",
      "Design efficient relational schemas that balance performance with data integrity"
    ],
    "intro": "The relational model, introduced by Edgar F. Codd in 1970, is the theoretical foundation of modern relational database management systems (RDBMS). It provides a mathematical framework for organizing and manipulating data using tables (relations), rows (tuples), and columns (attributes).\n\nAt the core of the relational model are fundamental concepts: relations (tables), tuples (rows), attributes (columns), domains (valid values for attributes), and keys (unique identifiers). These concepts ensure data integrity, consistency, and provide a solid foundation for complex data operations.\n\nNormalization is the process of organizing data to minimize redundancy and dependency anomalies. The normalization process involves decomposing tables into smaller, related tables while defining relationships between them. This lesson will cover the first three normal forms (1NF, 2NF, 3NF) and their practical applications in database design.\n\nUnderstanding these principles is crucial for designing databases that are both efficient and maintainable, ensuring data integrity while supporting complex queries and transactions in real-world applications.",
    "code": {
      "example": "-- First Normal Form (1NF) - Atomic values in each column\nCREATE TABLE unnormalized_orders (\n  order_id INT PRIMARY KEY,\n  customer_name VARCHAR(100),\n  products VARCHAR(500) -- Violation: 'ProductA, ProductB, ProductC'\n);\n\n-- 1NF compliant table\nCREATE TABLE orders_1nf (\n  order_id INT,\n  product_name VARCHAR(100),\n  quantity INT,\n  PRIMARY KEY (order_id, product_name)\n);\n\n-- Second Normal Form (2NF) - 1NF + no partial dependencies\n-- Violation: partial dependency on composite key\nCREATE TABLE order_details_bad (\n  order_id INT,\n  product_id INT,\n  customer_name VARCHAR(100), -- Depends only on order_id, not product_id\n  product_name VARCHAR(100),   -- Depends only on product_id, not order_id\n  quantity INT,\n  PRIMARY KEY (order_id, product_id)\n);\n\n-- 2NF compliant design\nCREATE TABLE orders (\n  order_id INT PRIMARY KEY,\n  customer_id INT,\n  order_date DATE\n);\n\nCREATE TABLE order_items (\n  order_id INT,\n  product_id INT,\n  quantity INT,\n  PRIMARY KEY (order_id, product_id)\n);\n\nCREATE TABLE customers (\n  customer_id INT PRIMARY KEY,\n  customer_name VARCHAR(100)\n);\n\nCREATE TABLE products (\n  product_id INT PRIMARY KEY,\n  product_name VARCHAR(100)\n);\n\n-- Third Normal Form (3NF) - 2NF + no transitive dependencies\n-- Violation: transitive dependency\nCREATE TABLE employees_bad (\n  employee_id INT PRIMARY KEY,\n  employee_name VARCHAR(100),\n  department_id INT,\n  department_name VARCHAR(100), -- Depends on department_id, not employee_id\n  manager_name VARCHAR(100)     -- Depends on department_id, not employee_id\n);\n\n-- 3NF compliant design\nCREATE TABLE departments (\n  department_id INT PRIMARY KEY,\n  department_name VARCHAR(100),\n  manager_name VARCHAR(100)\n);\n\nCREATE TABLE employees (\n  employee_id INT PRIMARY KEY,\n  employee_name VARCHAR(100),\n  department_id INT,\n  FOREIGN KEY (department_id) REFERENCES departments(department_id)\n);",
      "explanation": "This example demonstrates the progression from unnormalized data to properly normalized relational schemas:\n\n1. **First Normal Form (1NF)**: Eliminates repeating groups and ensures atomic values\n   - Multi-valued attributes are moved to separate rows\n   - Each cell contains only a single value\n\n2. **Second Normal Form (2NF)**: Removes partial dependencies\n   - Eliminates redundancy caused by composite primary keys\n   - Data that depends on only part of a composite key is moved to separate tables\n\n3. **Third Normal Form (3NF)**: Removes transitive dependencies\n   - Eliminates redundancy caused by non-key attributes depending on other non-key attributes\n   - Data that is indirectly dependent on the primary key is moved to separate tables\n\nThe output shows properly structured database schemas that follow normalization principles, ensuring data integrity and reducing redundancy.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Over-normalizing database schemas leading to excessive joins",
        "solution": "Balance normalization with performance requirements; consider denormalization for read-heavy applications",
        "severity": "medium"
      },
      {
        "mistake": "Ignoring business requirements in favor of theoretical normalization",
        "solution": "Apply normalization principles while considering real-world usage patterns and performance needs",
        "severity": "high"
      },
      {
        "mistake": "Violating atomicity by storing multiple values in a single column",
        "solution": "Use separate tables with foreign key relationships for multi-valued attributes",
        "severity": "high"
      }
    ],
    "exercises": [
      {
        "title": "Practice: Normalize a University Database Schema",
        "description": "Design a normalized database schema for a university system with students, courses, and enrollments",
        "checkpoints": [
          "Identify entities and their attributes in the university system",
          "Apply 1NF to eliminate repeating groups",
          "Apply 2NF to remove partial dependencies",
          "Apply 3NF to remove transitive dependencies",
          "Create appropriate primary and foreign keys"
        ]
      }
    ],
    "next": [
      "database-systems-lesson-2"
    ],
    "estimatedMinutes": 60,
    "difficulty": "Intermediate",
    "tags": [
      "Relational Model",
      "Normalization",
      "Database Design",
      "1NF",
      "2NF",
      "3NF"
    ],
    "sources": [
      {
        "title": "A Relational Model of Data for Large Shared Data Banks - E.F. Codd",
        "url": "https://www.seas.upenn.edu/~zives/03s/cis550/codd.pdf"
      },
      {
        "title": "Database System Concepts - Abraham Silberschatz, Henry F. Korth, S. Sudarshan",
        "url": "https://www.db-book.com/"
      },
      {
        "title": "Fundamentals of Database Systems - Ramez Elmasri, Shamkant B. Navathe",
        "url": "https://www.pearson.com/us/higher-education/program/Elmasri-Fundamentals-of-Database-Systems-7th-Edition/PGM118419.html"
      }
    ],
    "lastUpdated": "2025-10-02T10:00:00.000Z",
    "version": "1.1.0"
  },
  {
    "id": "database-systems-lesson-2",
    "moduleSlug": "database-systems",
    "title": "Keys, Constraints, and Indexes",
    "order": 2,
    "objectives": [
      "Implement primary keys, foreign keys, and unique constraints for data integrity",
      "Design and apply check constraints to enforce business rules at the database level",
      "Create and optimize indexes for query performance while considering maintenance costs"
    ],
    "intro": "Keys, constraints, and indexes are fundamental mechanisms for ensuring data integrity, enforcing business rules, and optimizing database performance. These features work together to create robust database systems that maintain consistency while providing efficient data access.\n\nKeys are attributes or combinations of attributes that uniquely identify rows in a table. Primary keys uniquely identify each row within a table, while foreign keys establish relationships between tables by referencing primary keys in other tables. Unique constraints ensure that specific columns or combinations of columns contain unique values.\n\nConstraints are rules applied to columns or tables that restrict the type of data that can be stored. Check constraints validate that column values meet specific conditions, not-null constraints prevent null values, and referential integrity constraints maintain consistency between related tables.\n\nIndexes are database structures that improve query performance by providing quick access paths to data. Different types of indexes, such as B-tree, hash, and bitmap indexes, are optimized for different query patterns. However, indexes also impose maintenance overhead during data modifications.\n\nThis lesson will explore these concepts in depth, showing how to properly implement them for robust database design and optimal performance.",
    "code": {
      "example": "-- Primary key constraint\nCREATE TABLE customers (\n  customer_id INT AUTO_INCREMENT,\n  email VARCHAR(255) NOT NULL,\n  first_name VARCHAR(100) NOT NULL,\n  last_name VARCHAR(100) NOT NULL,\n  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n  PRIMARY KEY (customer_id),\n  UNIQUE KEY uk_email (email)\n);\n\n-- Foreign key with referential actions\nCREATE TABLE orders (\n  order_id INT AUTO_INCREMENT,\n  customer_id INT NOT NULL,\n  order_date DATE NOT NULL,\n  total_amount DECIMAL(10,2) NOT NULL,\n  status ENUM('pending', 'processing', 'shipped', 'delivered', 'cancelled') DEFAULT 'pending',\n  PRIMARY KEY (order_id),\n  FOREIGN KEY fk_orders_customer (customer_id) REFERENCES customers(customer_id)\n    ON DELETE CASCADE ON UPDATE CASCADE,\n  INDEX idx_order_date (order_date),\n  INDEX idx_status (status)\n);\n\n-- Check constraints for business rules\nCREATE TABLE products (\n  product_id INT AUTO_INCREMENT,\n  name VARCHAR(255) NOT NULL,\n  price DECIMAL(10,2) NOT NULL,\n  category VARCHAR(100) NOT NULL,\n  stock_quantity INT NOT NULL DEFAULT 0,\n  discontinued BOOLEAN NOT NULL DEFAULT FALSE,\n  PRIMARY KEY (product_id),\n  CHECK (price > 0),\n  CHECK (stock_quantity >= 0),\n  INDEX idx_category (category)\n);\n\n-- Composite key and multiple constraints\nCREATE TABLE order_items (\n  order_id INT,\n  product_id INT,\n  quantity INT NOT NULL,\n  unit_price DECIMAL(10,2) NOT NULL,\n  PRIMARY KEY (order_id, product_id),\n  FOREIGN KEY fk_order_items_order (order_id) REFERENCES orders(order_id)\n    ON DELETE CASCADE,\n  FOREIGN KEY fk_order_items_product (product_id) REFERENCES products(product_id),\n  CHECK (quantity > 0),\n  CHECK (unit_price > 0)\n);\n\n-- Advanced indexing strategies\n-- Composite index for multi-column queries\nCREATE INDEX idx_customer_name ON customers (last_name, first_name);\n\n-- Partial index for filtered queries\nCREATE INDEX idx_active_orders ON orders (order_date) WHERE status != 'cancelled';\n\n-- Full-text index for text search\nCREATE FULLTEXT INDEX idx_product_name ON products (name);",
      "explanation": "This example demonstrates various keys, constraints, and indexes:\n\n1. **Primary and Unique Keys**: \n   - AUTO_INCREMENT primary key for unique row identification\n   - UNIQUE constraint on email to prevent duplicates\n\n2. **Foreign Keys with Referential Actions**:\n   - CASCADE actions for automatic cleanup when referenced rows are deleted/updated\n   - Indexes on foreign key columns for join performance\n\n3. **Check Constraints**:\n   - Business rule enforcement at the database level\n   - Prevention of invalid data entry\n\n4. **Indexing Strategies**:\n   - Composite indexes for multi-column queries\n   - Partial indexes for filtered queries\n   - Full-text indexes for text search\n\nThe output shows a well-structured database schema with proper integrity constraints and performance optimizations.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Creating too many indexes leading to performance degradation during writes",
        "solution": "Analyze query patterns and create only necessary indexes; regularly review index usage statistics",
        "severity": "high"
      },
      {
        "mistake": "Not defining appropriate referential actions for foreign keys",
        "solution": "Choose CASCADE, SET NULL, or RESTRICT based on business requirements and data integrity needs",
        "severity": "medium"
      },
      {
        "mistake": "Using generic constraint names that are difficult to understand",
        "solution": "Use descriptive names that clearly indicate the constraint's purpose (e.g., fk_orders_customer)",
        "severity": "low"
      }
    ],
    "exercises": [
      {
        "title": "Practice: Design a Library Management System Schema",
        "description": "Create a database schema for a library system with books, borrowers, and loans",
        "checkpoints": [
          "Define tables for books, borrowers, and loans with appropriate primary keys",
          "Implement foreign key relationships between tables",
          "Add check constraints for business rules (e.g., loan dates, return dates)",
          "Create indexes for common query patterns",
          "Ensure referential integrity with appropriate actions"
        ]
      }
    ],
    "next": [
      "database-systems-lesson-3"
    ],
    "estimatedMinutes": 55,
    "difficulty": "Intermediate",
    "tags": [
      "Keys",
      "Constraints",
      "Indexes",
      "Referential Integrity",
      "Performance Optimization"
    ],
    "sources": [
      {
        "title": "SQL for Web Nerds - Constraints Chapter",
        "url": "http://philip.greenspun.com/sql/constraints.html"
      },
      {
        "title": "Database Internals - Indexing Chapter",
        "url": "https://www.databass.dev/"
      },
      {
        "title": "MySQL 8.0 Reference Manual - Constraints",
        "url": "https://dev.mysql.com/doc/refman/8.0/en/create-table-constraints.html"
      }
    ],
    "lastUpdated": "2025-10-02T10:00:00.000Z",
    "version": "1.1.0"
  },
  {
    "id": "database-systems-lesson-3",
    "moduleSlug": "database-systems",
    "title": "Advanced Queries with Joins, Subqueries, and Set Operations",
    "order": 3,
    "objectives": [
      "Write complex queries using different types of joins for data retrieval",
      "Implement correlated and non-correlated subqueries for advanced filtering",
      "Apply set operations to combine results from multiple queries"
    ],
    "intro": "Advanced SQL queries are essential for extracting meaningful insights from complex database schemas. As applications grow in complexity, simple SELECT statements are insufficient for retrieving the data needed for reporting, analytics, and business intelligence.\n\nJoins are used to combine rows from two or more tables based on related columns. Different types of joins serve different purposes: INNER JOIN returns only matching rows, LEFT JOIN includes all rows from the left table, RIGHT JOIN includes all rows from the right table, and FULL OUTER JOIN includes all rows from both tables.\n\nSubqueries are queries nested within other queries, providing powerful capabilities for filtering, calculation, and data manipulation. Correlated subqueries reference columns from the outer query and are executed once for each row, while non-correlated subqueries are executed once and their results are used by the outer query.\n\nSet operations such as UNION, INTERSECT, and EXCEPT allow combining results from multiple queries. UNION combines results and removes duplicates, UNION ALL combines results including duplicates, INTERSECT returns only rows that appear in both queries, and EXCEPT returns rows from the first query that are not in the second.\n\nThis lesson will explore these advanced querying techniques with practical examples that demonstrate their real-world applications.",
    "code": {
      "example": "-- Different types of joins\n-- INNER JOIN: Only customers who have placed orders\nSELECT c.first_name, c.last_name, o.order_date, o.total_amount\nFROM customers c\nINNER JOIN orders o ON c.customer_id = o.customer_id\nORDER BY o.order_date DESC;\n\n-- LEFT JOIN: All customers, including those without orders\nSELECT c.first_name, c.last_name, COUNT(o.order_id) as order_count\nFROM customers c\nLEFT JOIN orders o ON c.customer_id = o.customer_id\nGROUP BY c.customer_id, c.first_name, c.last_name\nORDER BY order_count DESC;\n\n-- RIGHT JOIN: All orders, including those with invalid customer references\nSELECT c.first_name, c.last_name, o.order_date\nFROM customers c\nRIGHT JOIN orders o ON c.customer_id = o.customer_id\nWHERE c.customer_id IS NULL;\n\n-- Self JOIN: Find customers in the same city\nSELECT c1.first_name as customer1, c2.first_name as customer2, c1.city\nFROM customers c1\nINNER JOIN customers c2 ON c1.city = c2.city AND c1.customer_id < c2.customer_id;\n\n-- Correlated subquery: Customers with orders over $1000\nSELECT first_name, last_name\nFROM customers c\nWHERE EXISTS (\n  SELECT 1 FROM orders o \n  WHERE o.customer_id = c.customer_id AND o.total_amount > 1000\n);\n\n-- Non-correlated subquery: Customers who ordered the most expensive product\nSELECT first_name, last_name\nFROM customers\nWHERE customer_id IN (\n  SELECT customer_id FROM orders \n  WHERE order_id IN (\n    SELECT order_id FROM order_items \n    WHERE product_id = (\n      SELECT product_id FROM products \n      ORDER BY price DESC LIMIT 1\n    )\n  )\n);\n\n-- Set operations\n-- UNION: Combine customer and supplier names (removes duplicates)\nSELECT first_name, last_name FROM customers\nUNION\nSELECT contact_first_name, contact_last_name FROM suppliers\nORDER BY last_name, first_name;\n\n-- UNION ALL: Include all names including duplicates\nSELECT city FROM customers\nUNION ALL\nSELECT city FROM suppliers;\n\n-- INTERSECT: Cities that have both customers and suppliers (MySQL workaround)\nSELECT DISTINCT c.city\nFROM customers c\nINNER JOIN suppliers s ON c.city = s.city;\n\n-- EXCEPT: Cities with customers but no suppliers (MySQL workaround)\nSELECT DISTINCT city FROM customers\nWHERE city NOT IN (SELECT city FROM suppliers WHERE city IS NOT NULL);",
      "explanation": "This example demonstrates advanced querying techniques:\n\n1. **Join Types**:\n   - INNER JOIN for matching data only\n   - LEFT JOIN to include all rows from left table\n   - RIGHT JOIN to include all rows from right table\n   - Self JOIN for relationships within the same table\n\n2. **Subqueries**:\n   - Correlated subquery that executes for each row\n   - Nested non-correlated subqueries for complex filtering\n   - EXISTS for existence checks\n   - IN for membership tests\n\n3. **Set Operations**:\n   - UNION for combining results without duplicates\n   - UNION ALL for combining results with duplicates\n   - INTERSECT and EXCEPT workarounds for MySQL\n\nThe output shows various ways to retrieve and combine data from multiple tables, demonstrating the power of SQL for complex data analysis.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Using Cartesian products unintentionally by omitting JOIN conditions",
        "solution": "Always specify proper JOIN conditions; use EXPLAIN to verify query execution plans",
        "severity": "high"
      },
      {
        "mistake": "Writing inefficient correlated subqueries that perform poorly on large datasets",
        "solution": "Consider JOIN alternatives or ensure proper indexing for correlated subqueries",
        "severity": "high"
      },
      {
        "mistake": "Not considering NULL values in set operations and JOINs",
        "solution": "Explicitly handle NULL values with IS NULL/IS NOT NULL conditions and COALESCE functions",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Practice: Analyze Sales Data with Advanced Queries",
        "description": "Write queries to analyze sales performance and customer behavior",
        "checkpoints": [
          "Find top 10 customers by total spending using JOINs",
          "Identify products never ordered using subqueries",
          "Combine results from different time periods using set operations",
          "Calculate customer lifetime value with complex aggregations"
        ]
      }
    ],
    "next": [
      "database-systems-lesson-4"
    ],
    "estimatedMinutes": 65,
    "difficulty": "Advanced",
    "tags": [
      "Joins",
      "Subqueries",
      "Set Operations",
      "Data Analysis",
      "Complex Queries"
    ],
    "sources": [
      {
        "title": "SQL Cookbook - Query Solutions and Techniques",
        "url": "https://www.oreilly.com/library/view/sql-cookbook/0596009763/"
      },
      {
        "title": "Learning SQL - Alan Beaulieu",
        "url": "https://www.oreilly.com/library/view/learning-sql-2nd/9780596801835/"
      },
      {
        "title": "High Performance MySQL - Optimization and Tuning",
        "url": "https://www.oreilly.com/library/view/high-performance-mysql/9781492080503/"
      }
    ],
    "lastUpdated": "2025-10-02T10:00:00.000Z",
    "version": "1.1.0"
  },
  {
    "id": "database-systems-lesson-4",
    "moduleSlug": "database-systems",
    "title": "ER Diagrams and Advanced Relationships",
    "order": 4,
    "objectives": [
      "Implement practical solutions",
      "Build foundational understanding"
    ],
    "intro": "Welcome to this comprehensive lesson on Data Modeling.\n\nLearn how to create comprehensive Entity-Relationship diagrams and model complex relationships including inheritance and polymorphic associations.\n\nThroughout this lesson, you'll gain hands-on experience with practical implementations and real-world scenarios. We'll explore both the theoretical foundations and practical applications, ensuring you can immediately apply what you learn.\n\nThis lesson is designed to build upon previous concepts while introducing new techniques that will enhance your development skills. By the end, you'll have a solid understanding of the key principles and be ready to tackle more advanced topics.\n\nThe knowledge gained here will serve as a foundation for subsequent lessons and real-world projects.",
    "code": {
      "example": "-- One-to-One relationship (User Profile)\nCREATE TABLE users (\n  id INT PRIMARY KEY AUTO_INCREMENT,\n  username VARCHAR(50) UNIQUE NOT NULL\n);\n\nCREATE TABLE profiles (\n  id INT PRIMARY KEY AUTO_INCREMENT,\n  user_id INT UNIQUE,  -- UNIQUE constraint makes it one-to-one\n  bio TEXT,\n  website VARCHAR(100),\n  FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE\n);\n\n-- Many-to-Many with attributes (Enrollment with grades)\nCREATE TABLE students (\n  id INT PRIMARY KEY AUTO_INCREMENT,\n  name VARCHAR(100) NOT NULL\n);\n\nCREATE TABLE courses (\n  id INT PRIMARY KEY AUTO_INCREMENT,\n  title VARCHAR(100) NOT NULL,\n  credits INT DEFAULT 3\n);\n\nCREATE TABLE enrollments (\n  student_id INT,\n  course_id INT,\n  enrollment_date DATE,\n  grade CHAR(2),\n  PRIMARY KEY (student_id, course_id),\n  FOREIGN KEY (student_id) REFERENCES students(id) ON DELETE CASCADE,\n  FOREIGN KEY (course_id) REFERENCES courses(id) ON DELETE CASCADE\n);\n\n-- Hierarchical data (Adjacency List Model)\nCREATE TABLE categories (\n  id INT PRIMARY KEY AUTO_INCREMENT,\n  name VARCHAR(100) NOT NULL,\n  parent_id INT,\n  FOREIGN KEY (parent_id) REFERENCES categories(id)\n);\n\n-- Self-referencing relationship (Manager-Subordinate)\nCREATE TABLE employees (\n  id INT PRIMARY KEY AUTO_INCREMENT,\n  name VARCHAR(100) NOT NULL,\n  manager_id INT,\n  FOREIGN KEY (manager_id) REFERENCES employees(id)\n);",
      "explanation": "This example produces: Advanced database schema designs showing one-to-one relationships, many-to-many with attributes, and hierarchical data modeling\n\nThe code demonstrates practical implementation techniques and shows how the concepts work in real scenarios. Pay attention to the structure and patterns used, as these represent industry best practices.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Not following best practices",
        "solution": "Review documentation and community guidelines",
        "severity": "medium"
      },
      {
        "mistake": "Skipping error handling",
        "solution": "Implement proper error boundaries and validation",
        "severity": "low"
      }
    ],
    "exercises": [
      {
        "title": "Practice: ER Diagrams and Advanced Relationships",
        "description": "Apply the concepts from this lesson on Data Modeling",
        "checkpoints": [
          "Understand the core concept",
          "Implement the example code",
          "Experiment with variations"
        ]
      }
    ],
    "next": [],
    "estimatedMinutes": 25,
    "difficulty": "Advanced",
    "tags": [
      "Data Modeling",
      "database"
    ],
    "legacy": {
      "originalId": 4,
      "originalTopic": "Data Modeling",
      "migrated": "2025-10-01T06:41:13.481Z"
    },
    "lastUpdated": "2025-10-01T06:41:13.481Z",
    "version": "1.0.0"
  },
  {
    "id": "database-systems-lesson-5",
    "moduleSlug": "database-systems",
    "title": "Entity Framework Core Advanced Patterns",
    "order": 5,
    "objectives": [
      "Implement practical solutions",
      "Build foundational understanding"
    ],
    "intro": "Welcome to this comprehensive lesson on ORM Integration.\n\nLearn advanced Entity Framework Core patterns including lazy loading, eager loading, and performance optimization techniques.\n\nThroughout this lesson, you'll gain hands-on experience with practical implementations and real-world scenarios. We'll explore both the theoretical foundations and practical applications, ensuring you can immediately apply what you learn.\n\nThis lesson is designed to build upon previous concepts while introducing new techniques that will enhance your development skills. By the end, you'll have a solid understanding of the key principles and be ready to tackle more advanced topics.\n\nThe knowledge gained here will serve as a foundation for subsequent lessons and real-world projects.",
    "code": {
      "example": "// Entity classes with relationships\npublic class Blog\n{\n    public int BlogId { get; set; }\n    public string Url { get; set; } = string.Empty;\n    \n    // Navigation property for related posts\n    public List<Post> Posts { get; } = new();\n    \n    // One-to-one relationship\n    public BlogDetails? BlogDetails { get; set; }\n}\n\npublic class Post\n{\n    public int PostId { get; set; }\n    public string Title { get; set; } = string.Empty;\n    public string Content { get; set; } = string.Empty;\n    \n    // Foreign key\n    public int BlogId { get; set; }\n    \n    // Navigation property\n    public Blog Blog { get; set; } = null!;\n    \n    // Many-to-many relationship\n    public List<Tag> Tags { get; } = new();\n}\n\npublic class Tag\n{\n    public int TagId { get; set; }\n    public string Name { get; set; } = string.Empty;\n    \n    public List<Post> Posts { get; } = new();\n}\n\npublic class BlogDetails\n{\n    public int BlogDetailsId { get; set; }\n    public DateTime CreatedOn { get; set; }\n    public string Owner { get; set; } = string.Empty;\n    \n    public int BlogId { get; set; }\n    public Blog Blog { get; set; } = null!;\n}\n\n// DbContext with advanced configuration\npublic class BloggingContext : DbContext\n{\n    public DbSet<Blog> Blogs { get; set; }\n    public DbSet<Post> Posts { get; set; }\n    public DbSet<Tag> Tags { get; set; }\n    public DbSet<BlogDetails> BlogDetails { get; set; }\n    \n    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)\n    {\n        optionsBuilder.UseSqlServer(\n            @\"Server=(localdb)\\mssqllocaldb;Database=Blogging;Trusted_Connection=True\");\n    }\n    \n    protected override void OnModelCreating(ModelBuilder modelBuilder)\n    {\n        // Configure many-to-many relationship\n        modelBuilder.Entity<Post>()\n            .HasMany(p => p.Tags)\n            .WithMany(t => t.Posts)\n            .UsingEntity(j => j.ToTable(\"PostTags\"));\n            \n        // Configure indexes\n        modelBuilder.Entity<Blog>()\n            .HasIndex(b => b.Url)\n            .IsUnique();\n    }\n}\n\n// Query optimization examples\n// Eager loading to avoid N+1 problem\nvar blogs = context.Blogs\n    .Include(b => b.Posts)\n        .ThenInclude(p => p.Tags)\n    .ToList();\n    \n// Projection to load only needed data\nvar blogSummaries = context.Blogs\n    .Select(b => new { b.Url, PostCount = b.Posts.Count() })\n    .ToList();",
      "explanation": "This example produces: Advanced C# entity classes and DbContext configuration showing relationships, navigation properties, and performance optimization techniques\n\nThe code demonstrates practical implementation techniques and shows how the concepts work in real scenarios. Pay attention to the structure and patterns used, as these represent industry best practices.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Not following best practices",
        "solution": "Review documentation and community guidelines",
        "severity": "medium"
      },
      {
        "mistake": "Skipping error handling",
        "solution": "Implement proper error boundaries and validation",
        "severity": "low"
      }
    ],
    "exercises": [
      {
        "title": "Practice: Entity Framework Core Advanced Patterns",
        "description": "Apply the concepts from this lesson on ORM Integration",
        "checkpoints": [
          "Understand the core concept",
          "Implement the example code",
          "Experiment with variations"
        ]
      }
    ],
    "next": [],
    "estimatedMinutes": 25,
    "difficulty": "Advanced",
    "tags": [
      "ORM Integration",
      "database"
    ],
    "legacy": {
      "originalId": 5,
      "originalTopic": "ORM Integration",
      "migrated": "2025-10-01T06:41:13.481Z"
    },
    "lastUpdated": "2025-10-01T06:41:13.481Z",
    "version": "1.0.0"
  },
  {
    "id": "database-systems-lesson-6",
    "moduleSlug": "database-systems",
    "title": "ACID Properties and Transaction Management",
    "order": 6,
    "objectives": [
      "Implement practical solutions",
      "Build foundational understanding"
    ],
    "intro": "Welcome to this comprehensive lesson on Transactions.\n\nLearn about ACID properties, transaction isolation levels, and managing concurrent database operations.\n\nThroughout this lesson, you'll gain hands-on experience with practical implementations and real-world scenarios. We'll explore both the theoretical foundations and practical applications, ensuring you can immediately apply what you learn.\n\nThis lesson is designed to build upon previous concepts while introducing new techniques that will enhance your development skills. By the end, you'll have a solid understanding of the key principles and be ready to tackle more advanced topics.\n\nThe knowledge gained here will serve as a foundation for subsequent lessons and real-world projects.",
    "code": {
      "example": "-- Transaction with ACID properties\nSTART TRANSACTION;\n\n-- Atomicity: All operations succeed or all fail\nUPDATE accounts SET balance = balance - 100 WHERE id = 1;\nUPDATE accounts SET balance = balance + 100 WHERE id = 2;\n\n-- Check for errors and commit or rollback\nIF @@ERROR = 0\n  COMMIT;\nELSE\n  ROLLBACK;\n\n-- Isolation levels\nSET TRANSACTION ISOLATION LEVEL READ COMMITTED;\nSET TRANSACTION ISOLATION LEVEL REPEATABLE READ;\nSET TRANSACTION ISOLATION LEVEL SERIALIZABLE;\n\n-- Savepoints for partial rollbacks\nSTART TRANSACTION;\nINSERT INTO users (name, email) VALUES ('John', 'john@example.com');\nSAVEPOINT sp1;\nINSERT INTO orders (user_id, total) VALUES (1, 100);\n-- Rollback to savepoint if needed\nROLLBACK TO SAVEPOINT sp1;\nCOMMIT;",
      "explanation": "This example produces: Safe transaction handling with ACID compliance and rollback capabilities\n\nThe code demonstrates practical implementation techniques and shows how the concepts work in real scenarios. Pay attention to the structure and patterns used, as these represent industry best practices.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Not following best practices",
        "solution": "Review documentation and community guidelines",
        "severity": "medium"
      },
      {
        "mistake": "Skipping error handling",
        "solution": "Implement proper error boundaries and validation",
        "severity": "low"
      }
    ],
    "exercises": [
      {
        "title": "Practice: ACID Properties and Transaction Management",
        "description": "Apply the concepts from this lesson on Transactions",
        "checkpoints": [
          "Understand the core concept",
          "Implement the example code",
          "Experiment with variations"
        ]
      }
    ],
    "next": [],
    "estimatedMinutes": 25,
    "difficulty": "Intermediate",
    "tags": [
      "Transactions",
      "database"
    ],
    "legacy": {
      "originalId": 6,
      "originalTopic": "Transactions",
      "migrated": "2025-10-01T06:41:13.481Z"
    },
    "lastUpdated": "2025-10-01T06:41:13.481Z",
    "version": "1.0.0"
  },
  {
    "id": "database-systems-lesson-7",
    "moduleSlug": "database-systems",
    "title": "Query Optimization and Execution Plans",
    "order": 7,
    "objectives": [
      "Implement practical solutions",
      "Build foundational understanding"
    ],
    "intro": "Welcome to this comprehensive lesson on Performance.\n\nLearn how to analyze and optimize query performance using execution plans and indexing strategies.\n\nThroughout this lesson, you'll gain hands-on experience with practical implementations and real-world scenarios. We'll explore both the theoretical foundations and practical applications, ensuring you can immediately apply what you learn.\n\nThis lesson is designed to build upon previous concepts while introducing new techniques that will enhance your development skills. By the end, you'll have a solid understanding of the key principles and be ready to tackle more advanced topics.\n\nThe knowledge gained here will serve as a foundation for subsequent lessons and real-world projects.",
    "code": {
      "example": "-- Analyze query execution plan\nEXPLAIN SELECT u.name, COUNT(o.id) as order_count\nFROM users u\nLEFT JOIN orders o ON u.id = o.user_id\nWHERE u.created_at > '2023-01-01'\nGROUP BY u.id, u.name\nHAVING COUNT(o.id) > 5;\n\n-- Create indexes for better performance\nCREATE INDEX idx_users_created_at ON users(created_at);\nCREATE INDEX idx_orders_user_id ON orders(user_id);\nCREATE INDEX idx_composite ON orders(user_id, created_at);\n\n-- Query optimization techniques\n-- 1. Use LIMIT for large datasets\nSELECT * FROM products ORDER BY price DESC LIMIT 10;\n\n-- 2. Use EXISTS instead of IN for subqueries\nSELECT * FROM users u\nWHERE EXISTS (SELECT 1 FROM orders o WHERE o.user_id = u.id);\n\n-- 3. Avoid SELECT * in production\nSELECT id, name, email FROM users WHERE active = 1;\n\n-- Partitioning for large tables\nCREATE TABLE sales (\n  id INT,\n  sale_date DATE,\n  amount DECIMAL(10,2)\n) PARTITION BY RANGE (YEAR(sale_date)) (\n  PARTITION p2022 VALUES LESS THAN (2023),\n  PARTITION p2023 VALUES LESS THAN (2024),\n  PARTITION p2024 VALUES LESS THAN (2025)\n);",
      "explanation": "This example produces: Optimized queries with proper indexing and execution plan analysis\n\nThe code demonstrates practical implementation techniques and shows how the concepts work in real scenarios. Pay attention to the structure and patterns used, as these represent industry best practices.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Not following best practices",
        "solution": "Review documentation and community guidelines",
        "severity": "medium"
      },
      {
        "mistake": "Skipping error handling",
        "solution": "Implement proper error boundaries and validation",
        "severity": "low"
      }
    ],
    "exercises": [
      {
        "title": "Practice: Query Optimization and Execution Plans",
        "description": "Apply the concepts from this lesson on Performance",
        "checkpoints": [
          "Understand the core concept",
          "Implement the example code",
          "Experiment with variations"
        ]
      }
    ],
    "next": [],
    "estimatedMinutes": 25,
    "difficulty": "Advanced",
    "tags": [
      "Performance",
      "database"
    ],
    "legacy": {
      "originalId": 7,
      "originalTopic": "Performance",
      "migrated": "2025-10-01T06:41:13.481Z"
    },
    "lastUpdated": "2025-10-01T06:41:13.481Z",
    "version": "1.0.0"
  },
  {
    "id": "database-systems-lesson-8",
    "moduleSlug": "database-systems",
    "title": "Stored Procedures and User-Defined Functions",
    "order": 8,
    "objectives": [
      "Implement practical solutions",
      "Build foundational understanding"
    ],
    "intro": "Welcome to this comprehensive lesson on Functions.\n\nLearn how to create and use stored procedures and functions for business logic encapsulation.\n\nThroughout this lesson, you'll gain hands-on experience with practical implementations and real-world scenarios. We'll explore both the theoretical foundations and practical applications, ensuring you can immediately apply what you learn.\n\nThis lesson is designed to build upon previous concepts while introducing new techniques that will enhance your development skills. By the end, you'll have a solid understanding of the key principles and be ready to tackle more advanced topics.\n\nThe knowledge gained here will serve as a foundation for subsequent lessons and real-world projects.",
    "code": {
      "example": "-- Stored procedure with parameters\nDELIMITER //\nCREATE PROCEDURE GetUserOrders(\n  IN userId INT,\n  IN fromDate DATE,\n  OUT totalOrders INT,\n  OUT totalAmount DECIMAL(10,2)\n)\nBEGIN\n  DECLARE EXIT HANDLER FOR SQLEXCEPTION\n  BEGIN\n    ROLLBACK;\n    RESIGNAL;\n  END;\n  \n  START TRANSACTION;\n  \n  SELECT COUNT(*), COALESCE(SUM(total_amount), 0)\n  INTO totalOrders, totalAmount\n  FROM orders\n  WHERE user_id = userId AND order_date >= fromDate;\n  \n  COMMIT;\nEND //\nDELIMITER ;\n\n-- Call stored procedure\nCALL GetUserOrders(1, '2023-01-01', @orders, @amount);\nSELECT @orders, @amount;\n\n-- User-defined function\nDELIMITER //\nCREATE FUNCTION CalculateDiscount(\n  orderAmount DECIMAL(10,2),\n  customerType VARCHAR(20)\n) RETURNS DECIMAL(10,2)\nREADS SQL DATA\nDETERMINISTIC\nBEGIN\n  DECLARE discount DECIMAL(10,2) DEFAULT 0;\n  \n  CASE customerType\n    WHEN 'premium' THEN SET discount = orderAmount * 0.15;\n    WHEN 'gold' THEN SET discount = orderAmount * 0.10;\n    WHEN 'silver' THEN SET discount = orderAmount * 0.05;\n    ELSE SET discount = 0;\n  END CASE;\n  \n  RETURN discount;\nEND //\nDELIMITER ;\n\n-- Use function in query\nSELECT *, \n  CalculateDiscount(total_amount, customer_type) as discount\nFROM orders;",
      "explanation": "This example produces: Reusable stored procedures and functions for complex business logic\n\nThe code demonstrates practical implementation techniques and shows how the concepts work in real scenarios. Pay attention to the structure and patterns used, as these represent industry best practices.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Not following best practices",
        "solution": "Review documentation and community guidelines",
        "severity": "medium"
      },
      {
        "mistake": "Skipping error handling",
        "solution": "Implement proper error boundaries and validation",
        "severity": "low"
      }
    ],
    "exercises": [
      {
        "title": "Practice: Stored Procedures and User-Defined Functions",
        "description": "Apply the concepts from this lesson on Functions",
        "checkpoints": [
          "Understand the core concept",
          "Implement the example code",
          "Experiment with variations"
        ]
      }
    ],
    "next": [],
    "estimatedMinutes": 25,
    "difficulty": "Intermediate",
    "tags": [
      "Functions",
      "database"
    ],
    "legacy": {
      "originalId": 8,
      "originalTopic": "Functions",
      "migrated": "2025-10-01T06:41:13.481Z"
    },
    "lastUpdated": "2025-10-01T06:41:13.481Z",
    "version": "1.0.0"
  },
  {
    "id": "database-systems-lesson-9",
    "moduleSlug": "database-systems",
    "title": "Document Databases and MongoDB",
    "order": 9,
    "objectives": [
      "Implement practical solutions",
      "Build foundational understanding"
    ],
    "intro": "Welcome to this comprehensive lesson on NoSQL.\n\nLearn about NoSQL concepts and working with document databases like MongoDB.\n\nThroughout this lesson, you'll gain hands-on experience with practical implementations and real-world scenarios. We'll explore both the theoretical foundations and practical applications, ensuring you can immediately apply what you learn.\n\nThis lesson is designed to build upon previous concepts while introducing new techniques that will enhance your development skills. By the end, you'll have a solid understanding of the key principles and be ready to tackle more advanced topics.\n\nThe knowledge gained here will serve as a foundation for subsequent lessons and real-world projects.",
    "code": {
      "example": "// MongoDB document structure\n// Users collection\n{\n  \"_id\": ObjectId(\"507f1f77bcf86cd799439011\"),\n  \"name\": \"John Doe\",\n  \"email\": \"john@example.com\",\n  \"profile\": {\n    \"age\": 30,\n    \"interests\": [\"programming\", \"music\", \"travel\"],\n    \"address\": {\n      \"street\": \"123 Main St\",\n      \"city\": \"New York\",\n      \"zipcode\": \"10001\"\n    }\n  },\n  \"createdAt\": ISODate(\"2023-01-15T10:30:00Z\")\n}\n\n// MongoDB queries\n// Find documents\ndb.users.find({ \"profile.age\": { $gte: 18 } })\n\n// Complex query with multiple conditions\ndb.users.find({\n  $and: [\n    { \"profile.age\": { $gte: 25 } },\n    { \"profile.interests\": \"programming\" }\n  ]\n})\n\n// Update document\ndb.users.updateOne(\n  { \"_id\": ObjectId(\"507f1f77bcf86cd799439011\") },\n  { \n    $set: { \"profile.age\": 31 },\n    $push: { \"profile.interests\": \"reading\" }\n  }\n)\n\n// Aggregation pipeline\ndb.users.aggregate([\n  { $match: { \"profile.age\": { $gte: 25 } } },\n  { $group: {\n    _id: \"$profile.address.city\",\n    count: { $sum: 1 },\n    avgAge: { $avg: \"$profile.age\" }\n  }},\n  { $sort: { count: -1 } }\n])\n\n// Create index\ndb.users.createIndex({ \"email\": 1 }, { unique: true })\ndb.users.createIndex({ \"profile.age\": 1, \"profile.interests\": 1 })",
      "explanation": "This example produces: Flexible document storage with nested data structures and powerful querying capabilities\n\nThe code demonstrates practical implementation techniques and shows how the concepts work in real scenarios. Pay attention to the structure and patterns used, as these represent industry best practices.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Not following best practices",
        "solution": "Review documentation and community guidelines",
        "severity": "medium"
      },
      {
        "mistake": "Skipping error handling",
        "solution": "Implement proper error boundaries and validation",
        "severity": "low"
      }
    ],
    "exercises": [
      {
        "title": "Practice: Document Databases and MongoDB",
        "description": "Apply the concepts from this lesson on NoSQL",
        "checkpoints": [
          "Understand the core concept",
          "Implement the example code",
          "Experiment with variations"
        ]
      }
    ],
    "next": [],
    "estimatedMinutes": 25,
    "difficulty": "Intermediate",
    "tags": [
      "NoSQL",
      "database"
    ],
    "legacy": {
      "originalId": 9,
      "originalTopic": "NoSQL",
      "migrated": "2025-10-01T06:41:13.481Z"
    },
    "lastUpdated": "2025-10-01T06:41:13.481Z",
    "version": "1.0.0"
  },
  {
    "id": "database-systems-lesson-10",
    "moduleSlug": "database-systems",
    "title": "Database Backup and Recovery Strategies",
    "order": 10,
    "objectives": [
      "Implement practical solutions",
      "Build foundational understanding"
    ],
    "intro": "Welcome to this comprehensive lesson on Backup.\n\nLearn essential backup and recovery techniques to protect data integrity and business continuity.\n\nThroughout this lesson, you'll gain hands-on experience with practical implementations and real-world scenarios. We'll explore both the theoretical foundations and practical applications, ensuring you can immediately apply what you learn.\n\nThis lesson is designed to build upon previous concepts while introducing new techniques that will enhance your development skills. By the end, you'll have a solid understanding of the key principles and be ready to tackle more advanced topics.\n\nThe knowledge gained here will serve as a foundation for subsequent lessons and real-world projects.",
    "code": {
      "example": "-- Full database backup\nmysqldump -u root -p --all-databases > full_backup.sql\n\n-- Backup specific database with structure and data\nmysqldump -u root -p --databases myapp > myapp_backup.sql\n\n-- Backup only structure (schema)\nmysqldump -u root -p --no-data myapp > schema_backup.sql\n\n-- Backup only data\nmysqldump -u root -p --no-create-info myapp > data_backup.sql\n\n-- Point-in-time recovery setup\n-- Enable binary logging in my.cnf\nlog-bin=mysql-bin\nserver-id=1\nbinlog-format=ROW\n\n-- Create incremental backup\nmysqlbinlog mysql-bin.000001 > incremental_backup.sql\n\n-- Restore from backup\nmysql -u root -p < full_backup.sql\n\n-- Restore specific database\nmysql -u root -p myapp < myapp_backup.sql\n\n-- Automated backup script (bash)\n#!/bin/bash\nBACKUP_DIR=\"/var/backups/mysql\"\nDATE=$(date +%Y%m%d_%H%M%S)\nBACKUP_FILE=\"$BACKUP_DIR/backup_$DATE.sql\"\n\n# Create backup directory if it doesn't exist\nmkdir -p $BACKUP_DIR\n\n# Perform backup\nmysqldump -u backup_user -p$BACKUP_PASSWORD --all-databases > $BACKUP_FILE\n\n# Compress backup\ngzip $BACKUP_FILE\n\n# Remove backups older than 7 days\nfind $BACKUP_DIR -name \"*.gz\" -mtime +7 -delete\n\necho \"Backup completed: $BACKUP_FILE.gz\"",
      "explanation": "This example produces: Comprehensive backup solution with full, incremental, and automated backup strategies\n\nThe code demonstrates practical implementation techniques and shows how the concepts work in real scenarios. Pay attention to the structure and patterns used, as these represent industry best practices.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Not following best practices",
        "solution": "Review documentation and community guidelines",
        "severity": "medium"
      },
      {
        "mistake": "Skipping error handling",
        "solution": "Implement proper error boundaries and validation",
        "severity": "low"
      }
    ],
    "exercises": [
      {
        "title": "Practice: Database Backup and Recovery Strategies",
        "description": "Apply the concepts from this lesson on Backup",
        "checkpoints": [
          "Understand the core concept",
          "Implement the example code",
          "Experiment with variations"
        ]
      }
    ],
    "next": [],
    "estimatedMinutes": 25,
    "difficulty": "Intermediate",
    "tags": [
      "Backup",
      "database"
    ],
    "legacy": {
      "originalId": 10,
      "originalTopic": "Backup",
      "migrated": "2025-10-01T06:41:13.481Z"
    },
    "lastUpdated": "2025-10-01T06:41:13.481Z",
    "version": "1.0.0"
  },
  {
    "id": "database-systems-lesson-11",
    "moduleSlug": "database-systems",
    "title": "Database Security and Access Control",
    "order": 11,
    "objectives": [
      "Implement practical solutions",
      "Build foundational understanding"
    ],
    "intro": "Welcome to this comprehensive lesson on Security.\n\nLearn database security best practices including user management, encryption, and SQL injection prevention.\n\nThroughout this lesson, you'll gain hands-on experience with practical implementations and real-world scenarios. We'll explore both the theoretical foundations and practical applications, ensuring you can immediately apply what you learn.\n\nThis lesson is designed to build upon previous concepts while introducing new techniques that will enhance your development skills. By the end, you'll have a solid understanding of the key principles and be ready to tackle more advanced topics.\n\nThe knowledge gained here will serve as a foundation for subsequent lessons and real-world projects.",
    "code": {
      "example": "-- User management and privileges\n-- Create database user\nCREATE USER 'app_user'@'localhost' IDENTIFIED BY 'SecurePassword123!';\n\n-- Grant specific privileges\nGRANT SELECT, INSERT, UPDATE ON myapp.* TO 'app_user'@'localhost';\nGRANT EXECUTE ON PROCEDURE myapp.GetUserOrders TO 'app_user'@'localhost';\n\n-- Create read-only user\nCREATE USER 'readonly_user'@'%' IDENTIFIED BY 'ReadOnlyPass456!';\nGRANT SELECT ON myapp.* TO 'readonly_user'@'%';\n\n-- Revoke privileges\nREVOKE INSERT ON myapp.users FROM 'app_user'@'localhost';\n\n-- Show user privileges\nSHOW GRANTS FOR 'app_user'@'localhost';\n\n-- SQL injection prevention (parameterized queries)\n-- Vulnerable code (DON'T DO THIS)\n-- query = \"SELECT * FROM users WHERE id = \" + userId;\n\n-- Safe parameterized query (C#)\nstring query = \"SELECT * FROM users WHERE id = @userId\";\nusing var command = new MySqlCommand(query, connection);\ncommand.Parameters.AddWithValue(\"@userId\", userId);\n\n-- Data encryption\n-- Encrypt sensitive columns\nCREATE TABLE users (\n  id INT PRIMARY KEY AUTO_INCREMENT,\n  email VARCHAR(255),\n  ssn VARBINARY(255), -- Encrypted field\n  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Insert encrypted data\nINSERT INTO users (email, ssn) \nVALUES ('user@example.com', AES_ENCRYPT('123-45-6789', 'encryption_key'));\n\n-- Retrieve and decrypt\nSELECT email, AES_DECRYPT(ssn, 'encryption_key') as ssn_decrypted \nFROM users WHERE id = 1;\n\n-- Connection security\n-- Require SSL connections\nREQUIRE SSL;\nREQUIRE X509;\n\n-- Password policy\nSET GLOBAL validate_password.policy = STRONG;\nSET GLOBAL validate_password.length = 12;",
      "explanation": "This example produces: Secure database configuration with proper user privileges, encryption, and injection prevention\n\nThe code demonstrates practical implementation techniques and shows how the concepts work in real scenarios. Pay attention to the structure and patterns used, as these represent industry best practices.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Not following best practices",
        "solution": "Review documentation and community guidelines",
        "severity": "medium"
      },
      {
        "mistake": "Skipping error handling",
        "solution": "Implement proper error boundaries and validation",
        "severity": "low"
      }
    ],
    "exercises": [
      {
        "title": "Practice: Database Security and Access Control",
        "description": "Apply the concepts from this lesson on Security",
        "checkpoints": [
          "Understand the core concept",
          "Implement the example code",
          "Experiment with variations"
        ]
      }
    ],
    "next": [],
    "estimatedMinutes": 25,
    "difficulty": "Intermediate",
    "tags": [
      "Security",
      "database"
    ],
    "legacy": {
      "originalId": 11,
      "originalTopic": "Security",
      "migrated": "2025-10-01T06:41:13.481Z"
    },
    "lastUpdated": "2025-10-01T06:41:13.481Z",
    "version": "1.0.0"
  },
  {
    "id": "database-systems-lesson-12",
    "moduleSlug": "database-systems",
    "title": "Database Scaling and Replication",
    "order": 12,
    "objectives": [
      "Implement practical solutions",
      "Build foundational understanding"
    ],
    "intro": "Welcome to this comprehensive lesson on Advanced.\n\nLearn about database scaling techniques including replication, sharding, and distributed databases.\n\nThroughout this lesson, you'll gain hands-on experience with practical implementations and real-world scenarios. We'll explore both the theoretical foundations and practical applications, ensuring you can immediately apply what you learn.\n\nThis lesson is designed to build upon previous concepts while introducing new techniques that will enhance your development skills. By the end, you'll have a solid understanding of the key principles and be ready to tackle more advanced topics.\n\nThe knowledge gained here will serve as a foundation for subsequent lessons and real-world projects.",
    "code": {
      "example": "-- Master-Slave Replication Setup\n-- Master configuration (my.cnf)\nserver-id = 1\nlog-bin = mysql-bin\nbinlog-do-db = myapp\n\n-- Slave configuration (my.cnf)\nserver-id = 2\nrelay-log = mysql-relay-bin\nlog-slave-updates = 1\nread-only = 1\n\n-- Create replication user on master\nCREATE USER 'replicator'@'%' IDENTIFIED BY 'ReplicationPass123!';\nGRANT REPLICATION SLAVE ON *.* TO 'replicator'@'%';\nFLUSH PRIVILEGES;\n\n-- Get master status\nSHOW MASTER STATUS;\n\n-- Configure slave\nCHANGE MASTER TO\n  MASTER_HOST='master_ip',\n  MASTER_USER='replicator',\n  MASTER_PASSWORD='ReplicationPass123!',\n  MASTER_LOG_FILE='mysql-bin.000001',\n  MASTER_LOG_POS=154;\n\nSTART SLAVE;\nSHOW SLAVE STATUS\\G\n\n-- Horizontal partitioning (sharding) example\n-- Shard 1: Users with ID 1-1000\nCREATE TABLE users_shard1 (\n  id INT PRIMARY KEY CHECK (id BETWEEN 1 AND 1000),\n  name VARCHAR(100),\n  email VARCHAR(100)\n);\n\n-- Shard 2: Users with ID 1001-2000\nCREATE TABLE users_shard2 (\n  id INT PRIMARY KEY CHECK (id BETWEEN 1001 AND 2000),\n  name VARCHAR(100),\n  email VARCHAR(100)\n);\n\n-- Application-level sharding logic (pseudo-code)\nfunction getUserShard(userId) {\n  if (userId <= 1000) return 'shard1';\n  if (userId <= 2000) return 'shard2';\n  return 'shard3';\n}\n\n-- Read replica load balancing\n-- Write operations go to master\nINSERT INTO users (name, email) VALUES ('John', 'john@example.com');\n\n-- Read operations can use replicas\nSELECT * FROM users WHERE id = 123; -- Can be routed to read replica\n\n-- Connection pooling configuration\nmax_connections = 200\nmax_connect_errors = 100\nconnect_timeout = 10\nwait_timeout = 28800",
      "explanation": "This example produces: Scalable database architecture with replication, sharding, and load balancing for high availability\n\nThe code demonstrates practical implementation techniques and shows how the concepts work in real scenarios. Pay attention to the structure and patterns used, as these represent industry best practices.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Not following best practices",
        "solution": "Review documentation and community guidelines",
        "severity": "medium"
      },
      {
        "mistake": "Skipping error handling",
        "solution": "Implement proper error boundaries and validation",
        "severity": "low"
      }
    ],
    "exercises": [
      {
        "title": "Practice: Database Scaling and Replication",
        "description": "Apply the concepts from this lesson on Advanced",
        "checkpoints": [
          "Understand the core concept",
          "Implement the example code",
          "Experiment with variations"
        ]
      }
    ],
    "next": [],
    "estimatedMinutes": 25,
    "difficulty": "Intermediate",
    "tags": [
      "Advanced",
      "database"
    ],
    "legacy": {
      "originalId": 12,
      "originalTopic": "Advanced",
      "migrated": "2025-10-01T06:41:13.481Z"
    },
    "lastUpdated": "2025-10-01T06:41:13.481Z",
    "version": "1.0.0"
  },
  {
    "id": "database-systems-lesson-13",
    "moduleSlug": "database-systems",
    "title": "Database Security and Access Control",
    "order": 13,
    "objectives": [
      "Implement database security best practices",
      "Configure user roles and permissions",
      "Understand SQL injection prevention"
    ],
    "intro": "Database security is critical for protecting sensitive data and ensuring compliance with regulations. Understanding security principles helps prevent data breaches and unauthorized access.\n\nIn this lesson, you'll learn about authentication, authorization, and access control mechanisms in database systems. You'll understand how to create secure user accounts, assign appropriate permissions, and implement the principle of least privilege.\n\nSQL injection is one of the most common security vulnerabilities. You'll discover how to prevent injection attacks through parameterized queries, input validation, and secure coding practices that protect against malicious attacks.\n\nData encryption, both at rest and in transit, provides additional security layers. You'll learn when and how to implement encryption strategies that protect sensitive information while maintaining acceptable performance levels.",
    "code": {
      "example": "-- Creating database users with limited privileges\nCREATE USER 'app_read'@'localhost' IDENTIFIED BY 'secure_password123';\nCREATE USER 'app_write'@'localhost' IDENTIFIED BY 'secure_password456';\nCREATE USER 'admin_user'@'localhost' IDENTIFIED BY 'admin_password789';\n\n-- Granting specific permissions\nGRANT SELECT ON myapp.* TO 'app_read'@'localhost';\nGRANT SELECT, INSERT, UPDATE ON myapp.users TO 'app_write'@'localhost';\nGRANT ALL PRIVILEGES ON myapp.* TO 'admin_user'@'localhost';\n\n-- SQL injection prevention with prepared statements\n-- BAD: Vulnerable to SQL injection\n-- query = \"SELECT * FROM users WHERE email = '\" + email + \"'\";\n\n-- GOOD: Using parameterized queries\nPREPARE stmt FROM 'SELECT * FROM users WHERE email = ? AND active = ?';\nSET @email = 'user@example.com';\nSET @active = 1;\nEXECUTE stmt USING @email, @active;\nDEALLOCATE PREPARE stmt;\n\n-- Creating encrypted columns\nCREATE TABLE sensitive_data (\n  id INT PRIMARY KEY AUTO_INCREMENT,\n  user_id INT NOT NULL,\n  encrypted_ssn VARBINARY(255),\n  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n  FOREIGN KEY (user_id) REFERENCES users(id)\n);\n\n-- Inserting encrypted data\nINSERT INTO sensitive_data (user_id, encrypted_ssn) \nVALUES (1, AES_ENCRYPT('123-45-6789', 'encryption_key'));\n\n-- Retrieving and decrypting data\nSELECT user_id, AES_DECRYPT(encrypted_ssn, 'encryption_key') as ssn \nFROM sensitive_data WHERE user_id = 1;",
      "explanation": "This example demonstrates database security implementation including user privilege management, SQL injection prevention through parameterized queries, and data encryption techniques.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Using string concatenation for SQL queries",
        "solution": "Always use parameterized queries or prepared statements to prevent SQL injection",
        "severity": "high"
      },
      {
        "mistake": "Granting excessive privileges to application users",
        "solution": "Follow principle of least privilege - grant only necessary permissions",
        "severity": "high"
      },
      {
        "mistake": "Storing sensitive data in plain text",
        "solution": "Encrypt sensitive data and use secure key management practices",
        "severity": "high"
      }
    ],
    "exercises": [
      {
        "title": "Database Security Implementation",
        "description": "Implement comprehensive security measures for a database application.",
        "checkpoints": [
          "Create appropriate user roles with limited privileges",
          "Write secure queries using parameterized statements",
          "Implement data encryption for sensitive fields",
          "Audit and test security measures"
        ]
      }
    ],
    "next": [],
    "estimatedMinutes": 35,
    "difficulty": "Advanced",
    "tags": ["Security", "Access Control", "SQL Injection"],
    "lastUpdated": "2025-10-01T12:00:00.000Z",
    "version": "1.0.0"
  },
  {
    "id": "database-systems-lesson-14",
    "moduleSlug": "database-systems",
    "title": "Database Performance Tuning",
    "order": 14,
    "objectives": [
      "Analyze and optimize database performance",
      "Understand query execution plans",
      "Implement effective indexing strategies"
    ],
    "intro": "Database performance optimization is essential for applications that handle large datasets and high user loads. Understanding performance principles helps create responsive, scalable database systems.\n\nIn this lesson, you'll learn to analyze query execution plans to identify performance bottlenecks. Execution plans reveal how the database processes queries and help optimize slow-running operations through better indexing and query structure.\n\nIndexing strategies significantly impact database performance. You'll discover when to create indexes, how to design composite indexes effectively, and understand the trade-offs between query speed and write performance in different scenarios.\n\nQuery optimization techniques include proper join ordering, avoiding unnecessary subqueries, and leveraging database-specific features. You'll learn to rewrite queries for better performance while maintaining correctness and readability.",
    "code": {
      "example": "-- Analyzing query performance\nEXPLAIN SELECT u.first_name, u.last_name, COUNT(o.id) as order_count\nFROM users u\nLEFT JOIN orders o ON u.id = o.user_id\nWHERE u.created_at > '2024-01-01'\nGROUP BY u.id, u.first_name, u.last_name\nORDER BY order_count DESC\nLIMIT 10;\n\n-- Creating optimized indexes\n-- Composite index for common query patterns\nCREATE INDEX idx_user_created_active ON users(created_at, active);\nCREATE INDEX idx_order_user_date ON orders(user_id, order_date);\n\n-- Covering index (includes all needed columns)\nCREATE INDEX idx_user_covering ON users(id, first_name, last_name, email);\n\n-- Performance optimization techniques\n-- Use EXISTS instead of IN for large subqueries\nSELECT first_name, last_name FROM users u\nWHERE EXISTS (\n  SELECT 1 FROM orders o \n  WHERE o.user_id = u.id AND o.total_amount > 1000\n);\n\n-- Optimize with LIMIT to avoid scanning entire table\nSELECT * FROM products \nWHERE category_id = 5 \nORDER BY created_at DESC \nLIMIT 20;\n\n-- Use proper data types to save space and improve performance\nALTER TABLE products \nMODIFY COLUMN active BOOLEAN DEFAULT TRUE,\nMODIFY COLUMN price DECIMAL(8,2);\n\n-- Partitioning for large tables\nCREATE TABLE orders_2024 (\n  order_id INT AUTO_INCREMENT,\n  user_id INT NOT NULL,\n  order_date DATE NOT NULL,\n  total_amount DECIMAL(10,2),\n  PRIMARY KEY (order_id, order_date)\n) PARTITION BY RANGE (YEAR(order_date)) (\n  PARTITION p2024 VALUES LESS THAN (2025),\n  PARTITION p2025 VALUES LESS THAN (2026)\n);",
      "explanation": "This example demonstrates performance optimization techniques including execution plan analysis, strategic indexing, query optimization, and table partitioning for large datasets.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Creating too many indexes on frequently updated tables",
        "solution": "Balance read performance with write performance - avoid excessive indexing",
        "severity": "medium"
      },
      {
        "mistake": "Not analyzing execution plans before optimization",
        "solution": "Always use EXPLAIN to understand query performance before making changes",
        "severity": "high"
      },
      {
        "mistake": "Optimizing for edge cases instead of common queries",
        "solution": "Focus optimization efforts on frequently executed queries with real performance impact",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "Database Performance Analysis",
        "description": "Analyze and optimize a slow-performing database application.",
        "checkpoints": [
          "Identify slow queries using execution plans",
          "Create appropriate indexes to improve performance",
          "Optimize query structure and joins",
          "Measure and validate performance improvements"
        ]
      }
    ],
    "next": [],
    "estimatedMinutes": 40,
    "difficulty": "Advanced",
    "tags": ["Performance", "Optimization", "Indexing"],
    "lastUpdated": "2025-10-01T12:00:00.000Z",
    "version": "1.0.0"
  },
  {
    "id": "database-systems-lesson-15",
    "moduleSlug": "database-systems",
    "title": "NoSQL Databases and Document Stores",
    "order": 15,
    "objectives": [
      "Understand NoSQL database types and use cases",
      "Work with document databases like MongoDB",
      "Compare SQL vs NoSQL trade-offs"
    ],
    "intro": "NoSQL databases provide flexible, scalable alternatives to traditional relational databases for specific use cases. Understanding NoSQL principles helps choose the right database technology for different applications.\n\nDocument databases like MongoDB store data in flexible, JSON-like documents rather than rigid table structures. This approach works well for applications with evolving schemas, hierarchical data, or rapid development cycles requiring frequent changes.\n\nNoSQL databases excel at horizontal scaling, handling large volumes of unstructured data, and providing high availability through distributed architectures. You'll learn when these advantages outweigh the consistency guarantees of traditional SQL databases.\n\nCAP theorem explains the trade-offs between Consistency, Availability, and Partition tolerance in distributed systems. Understanding these concepts helps make informed decisions about database architecture for different application requirements.",
    "code": {
      "example": "// MongoDB document structure\n// Users collection with embedded documents\n{\n  \"_id\": ObjectId(\"507f1f77bcf86cd799439011\"),\n  \"firstName\": \"John\",\n  \"lastName\": \"Doe\",\n  \"email\": \"john@example.com\",\n  \"profile\": {\n    \"bio\": \"Software developer\",\n    \"website\": \"https://johndoe.com\",\n    \"location\": \"San Francisco, CA\"\n  },\n  \"orders\": [\n    {\n      \"orderId\": \"ORD-001\",\n      \"date\": ISODate(\"2024-01-15\"),\n      \"total\": 299.99,\n      \"items\": [\n        { \"productId\": \"PROD-123\", \"name\": \"Laptop\", \"price\": 299.99 }\n      ]\n    }\n  ],\n  \"preferences\": {\n    \"newsletter\": true,\n    \"notifications\": {\n      \"email\": true,\n      \"sms\": false\n    }\n  },\n  \"createdAt\": ISODate(\"2024-01-01\"),\n  \"updatedAt\": ISODate(\"2024-01-15\")\n}\n\n// MongoDB queries\n// Find users with orders over $200\ndb.users.find({\n  \"orders.total\": { $gt: 200 }\n});\n\n// Update nested document\ndb.users.updateOne(\n  { \"email\": \"john@example.com\" },\n  { \n    $set: { \n      \"profile.bio\": \"Senior Software Developer\",\n      \"updatedAt\": new Date()\n    }\n  }\n);\n\n// Aggregation pipeline\ndb.users.aggregate([\n  { $unwind: \"$orders\" },\n  { $group: {\n    _id: null,\n    totalRevenue: { $sum: \"$orders.total\" },\n    averageOrder: { $avg: \"$orders.total\" },\n    orderCount: { $sum: 1 }\n  }}\n]);\n\n// Creating indexes in MongoDB\ndb.users.createIndex({ \"email\": 1 }, { unique: true });\ndb.users.createIndex({ \"orders.date\": -1 });\ndb.users.createIndex({ \"profile.location\": 1, \"createdAt\": -1 });",
      "explanation": "This example demonstrates MongoDB document structure with embedded data, complex queries using MongoDB syntax, and aggregation operations for data analysis.",
      "language": "javascript"
    },
    "pitfalls": [
      {
        "mistake": "Over-embedding documents without considering query patterns",
        "solution": "Design document structure based on how data will be accessed and updated",
        "severity": "medium"
      },
      {
        "mistake": "Ignoring eventual consistency implications",
        "solution": "Understand consistency models and design application logic accordingly",
        "severity": "high"
      },
      {
        "mistake": "Not planning for data growth and scaling",
        "solution": "Consider sharding strategies and data distribution from the beginning",
        "severity": "medium"
      }
    ],
    "exercises": [
      {
        "title": "NoSQL Database Design",
        "description": "Design and implement a document-based data model for a real-world application.",
        "checkpoints": [
          "Choose appropriate document structure for the use case",
          "Implement queries for common access patterns",
          "Create indexes to optimize performance",
          "Compare with equivalent relational design"
        ]
      }
    ],
    "next": [],
    "estimatedMinutes": 35,
    "difficulty": "Intermediate",
    "tags": ["NoSQL", "MongoDB", "Document Database"],
    "lastUpdated": "2025-10-01T12:00:00.000Z",
    "version": "1.0.0"
  },
  {
    "id": "database-systems-lesson-16",
    "moduleSlug": "database-systems",
    "title": "Database Administration and Monitoring",
    "order": 16,
    "objectives": [
      "Understand database administration responsibilities",
      "Implement backup and recovery strategies",
      "Monitor database health and performance"
    ],
    "intro": "Database administration ensures reliable, secure, and performant database systems in production environments. Understanding DBA responsibilities helps maintain data integrity and system availability.\n\nBackup and recovery strategies protect against data loss from hardware failures, human errors, or security incidents. You'll learn different backup types, recovery procedures, and how to test disaster recovery plans effectively.\n\nDatabase monitoring provides visibility into system health, performance trends, and potential issues before they impact users. Effective monitoring includes tracking key metrics, setting up alerts, and analyzing logs for troubleshooting.\n\nMaintenance tasks like index optimization, statistics updates, and capacity planning ensure continued database performance. You'll understand how to schedule and automate routine maintenance while minimizing disruption to applications.",
    "code": {
      "example": "-- Database backup strategies\n-- Full backup (complete database)\nBACKUP DATABASE myapp TO DISK = '/backups/myapp_full_20241001.bak'\nWITH FORMAT, COMPRESSION;\n\n-- Differential backup (changes since last full backup)\nBACKUP DATABASE myapp TO DISK = '/backups/myapp_diff_20241001.bak'\nWITH DIFFERENTIAL, COMPRESSION;\n\n-- Transaction log backup (for point-in-time recovery)\nBACKUP LOG myapp TO DISK = '/backups/myapp_log_20241001.trn';\n\n-- Database restoration\nRESTORE DATABASE myapp FROM DISK = '/backups/myapp_full_20241001.bak'\nWITH NORECOVERY;\nRESTORE DATABASE myapp FROM DISK = '/backups/myapp_diff_20241001.bak'\nWITH RECOVERY;\n\n-- Performance monitoring queries\n-- Check database size and growth\nSELECT \n  table_schema as 'Database',\n  table_name as 'Table',\n  ROUND(((data_length + index_length) / 1024 / 1024), 2) as 'Size (MB)'\nFROM information_schema.tables\nORDER BY (data_length + index_length) DESC;\n\n-- Monitor slow queries\nSELECT \n  query_time,\n  lock_time,\n  rows_sent,\n  rows_examined,\n  sql_text\nFROM mysql.slow_log\nWHERE start_time > DATE_SUB(NOW(), INTERVAL 1 HOUR)\nORDER BY query_time DESC;\n\n-- Check index usage\nSELECT \n  object_name,\n  index_name,\n  user_seeks,\n  user_scans,\n  user_lookups,\n  user_updates\nFROM sys.dm_db_index_usage_stats\nWHERE database_id = DB_ID('myapp');\n\n-- Database maintenance\n-- Update table statistics\nUPDATE STATISTICS users;\nUPDATE STATISTICS orders;\n\n-- Rebuild fragmented indexes\nALTER INDEX ALL ON users REBUILD;\n\n-- Check database integrity\nDBCC CHECKDB('myapp') WITH NO_INFOMSGS;",
      "explanation": "This example demonstrates database administration tasks including backup/recovery procedures, performance monitoring queries, and routine maintenance operations.",
      "language": "sql"
    },
    "pitfalls": [
      {
        "mistake": "Not testing backup and recovery procedures regularly",
        "solution": "Regularly test restore procedures to ensure backups are valid and recovery works",
        "severity": "high"
      },
      {
        "mistake": "Ignoring database growth and capacity planning",
        "solution": "Monitor database growth trends and plan for capacity needs proactively",
        "severity": "medium"
      },
      {
        "mistake": "Not monitoring database performance metrics",
        "solution": "Implement comprehensive monitoring with alerts for key performance indicators",
        "severity": "high"
      }
    ],
    "exercises": [
      {
        "title": "Database Administration Setup",
        "description": "Implement comprehensive database administration procedures.",
        "checkpoints": [
          "Create automated backup schedule with full and incremental backups",
          "Test database recovery procedures",
          "Set up monitoring for key performance metrics",
          "Create maintenance plan for routine database tasks"
        ]
      }
    ],
    "next": [],
    "estimatedMinutes": 45,
    "difficulty": "Advanced",
    "tags": ["Administration", "Backup", "Monitoring"],
    "lastUpdated": "2025-10-01T12:00:00.000Z",
    "version": "1.0.0"
  }
]